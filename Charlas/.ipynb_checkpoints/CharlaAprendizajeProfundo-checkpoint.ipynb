{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "  <h1>Introducción al Aprendizaje Profundo</h1>\n",
    "  <h5>Dr. Wladimir Rodríguez</h5>\n",
    "  <h5>wladimir.rodriguez@gmail.com</h5>\n",
    "  <h5>Prof. Titular</h5>\n",
    "  <h5>Postgrado de Computación</h5>\n",
    "  <h5>Universidad de Los Andes</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demostración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplo de Inicio a Fin de un Problema de Aprendizaje Automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "- Arquitectura de las Redes Neuronales Convolucionales\n",
    "- Exploración de los Datos\n",
    "- Preprocesamiento de los Datos\n",
    "- Construir el Modelo de la Red neuronal\n",
    "- Entrenar el Modelo\n",
    "- Evaluar el Modelo\n",
    "- Prevenir el Sobreajuste\n",
    "- Reevaluar el Modelo\n",
    "- Generar un Reporte de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arquitectura de la Redes Neuronales Convolucionales\n",
    "\n",
    "<img src=\"../figuras/ArquitecturaRNC_MNIST.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## El conjunto de datos Fashion-MNIST\n",
    "\n",
    "El conjunto de datos Fashion-MNIST es un conjunto de datos de imágenes de artículos de Zalando, con 28x28 imágenes en escala de grises de 70,000 productos de moda de 10 categorías y 7,000 imágenes por categoría. El conjunto de entrenamiento tiene 60,000 imágenes, y el conjunto de prueba tiene 10,000 imágenes.\n",
    "\n",
    "Puede encontrar el conjunto de datos Fashion-MNIST en este [enlace](https://github.com/zalandoresearch/fashion-mnist), pero también puede cargarlo con la ayuda de módulos específicos de TensorFlow y Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"../figuras/fashion-mnist-sprite.png\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 7us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 42s 2us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 7s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_entrenamiento, y_entrenamiento), (X_prueba, y_prueba) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Explorar los Datos\n",
    "\n",
    "Analicemos ahora cómo son las imágenes en el conjunto de datos. Aunque ya conozca la dimensión de las imágenes, todavía vale la pena analizarlas programáticamente: es posible que deba volver a escalar los píxeles de la imagen y cambiar el tamaño de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del Conjunto de Entrenamiento:  (60000, 28, 28) (60000,)\n",
      "Dimensiones del Conjunto de Prueba:  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Dimensiones del Conjunto de Entrenamiento: ', X_entrenamiento.shape, y_entrenamiento.shape)\n",
    "\n",
    "print('Dimensiones del Conjunto de Prueba: ', X_prueba.shape, y_prueba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Encontrar cuantas etiquetas de clases existen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero total de salidas :  10\n",
      "Clases de salida :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Encontrar cuantas etiquetas de clases existen\n",
    "clases = np.unique(y_entrenamiento)\n",
    "num_clases = len(clases)\n",
    "print('Numero total de salidas : ', num_clases)\n",
    "print('Clases de salida : ', clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Visualizar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Visualizar la priemar imagen del conjunto de entrenamiento\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Visualizar la priemar imagen del conjunto de prueba\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referencia\n",
    "\n",
    "- [Convolutional Neural Networks in Python with Keras](https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
